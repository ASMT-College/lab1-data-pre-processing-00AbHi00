{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUiBY6oapJXrMoUtNHsjdK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASMT-College/lab1-data-pre-processing-00AbHi00/blob/main/tocLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nk2ZRuIaQnO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LAB 1: Using Pandas for Data Cleaning:\n",
        "<ul>\n",
        "  <li> Filling NA values </li>\n",
        "  <li> Removing null values </li>\n",
        "  <li> Standaization (Repalcing) values to maintain consitency </li>\n",
        "  <li> Drop Duplicate values </li> <br/>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "x6oNUl6aSj8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/data/employee_data.csv')\n",
        "\n",
        "print('NULL Age:',df['Age'].isnull().sum())\n",
        "print('NULL salary:',df['Salary'].isnull().sum())\n",
        "print(df['Department'].unique())\n",
        "print(df['Department'].nunique())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oaoPKtGhEH0",
        "outputId": "d5914b7d-9014-4017-aebf-39036134763c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NULL Age: 1\n",
            "NULL salary: 1\n",
            "['HR' 'Finance' 'Human Resources' 'IT' 'H.R.']\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)\n",
        "\n",
        "# Filling in NA values\n",
        "df['Age']=df['Age'].fillna(df['Age'].mean())\n",
        "\n",
        "\n",
        "\n",
        "# Standardization, converting each tuple to value\n",
        "df['Department']=df['Department'].replace(\n",
        "    {\n",
        "      'HR':'HR',\n",
        "      'Human Resources':'HR',\n",
        "      'H.R.':'HR'\n",
        "    }\n",
        ")\n",
        "\n",
        "print(df['Department'].unique())\n",
        "print(df)\n",
        "\n",
        "# There are no null values in this\n",
        "print('Null values',df['Age'].isnull().sum())\n",
        "\n",
        "\n",
        "# Removing duplicates based on ID, there is no duplicated ID\n",
        "print(df[df['ID'].duplicated()])\n",
        "\n",
        "#Getting values which are duplicated\n",
        "duplicated_rows = df[df.duplicated(subset=['Name', 'Age', 'Department'], keep='first')]\n",
        "\n",
        "\n",
        "print('Rows duplicated on Name, Age and Department are:')\n",
        "print(duplicated_rows)\n",
        "df.drop_duplicates(subset=['Age','Name', 'Department'], keep='first',inplace=True)\n",
        "\n",
        "print('final DF', df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aKameeheTzA",
        "outputId": "6151358c-af69-4324-9510-aaf9f2d7e122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HR' 'Finance' 'IT']\n",
            "    ID     Name   Age Department   Salary\n",
            "0    1     John  28.0         HR  50000.0\n",
            "1    2     Jane  35.0    Finance  60000.0\n",
            "2    3    Emily  35.7         HR  55000.0\n",
            "3    4  Michael  40.0         HR      NaN\n",
            "4    5    Sarah  29.0         IT  52000.0\n",
            "5    6    David  50.0    Finance  75000.0\n",
            "6    7    Laura  38.0         HR  68000.0\n",
            "7    8   Robert  32.0         HR  57000.0\n",
            "8    9    Linda  45.0         IT  62000.0\n",
            "9   10    James  30.0         HR  51000.0\n",
            "10  11    James  30.0         HR  51000.0\n",
            "Null values 0\n",
            "Empty DataFrame\n",
            "Columns: [ID, Name, Age, Department, Salary]\n",
            "Index: []\n",
            "Rows duplicated on Name, Age and Department are:\n",
            "    ID   Name   Age Department   Salary\n",
            "10  11  James  30.0         HR  51000.0\n",
            "final DF    ID     Name   Age Department   Salary\n",
            "0   1     John  28.0         HR  50000.0\n",
            "1   2     Jane  35.0    Finance  60000.0\n",
            "2   3    Emily  35.7         HR  55000.0\n",
            "3   4  Michael  40.0         HR      NaN\n",
            "4   5    Sarah  29.0         IT  52000.0\n",
            "5   6    David  50.0    Finance  75000.0\n",
            "6   7    Laura  38.0         HR  68000.0\n",
            "7   8   Robert  32.0         HR  57000.0\n",
            "8   9    Linda  45.0         IT  62000.0\n",
            "9  10    James  30.0         HR  51000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 2: Normalization"
      ],
      "metadata": {
        "id": "G7ZFjGIrUK_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def minMax(currVal, minVal, maxVal):\n",
        "  return (currVal-minVal)/(maxVal-minVal)\n",
        "\n",
        "\n",
        "list1=[10,20,3,45,23,80,10]\n",
        "normalizedList=[]\n",
        "\n",
        "# z= lambda x,y: x/y\n",
        "# print(z(10,20))\n",
        "\n",
        "for i in range(0, len(list1)):\n",
        "  normalizedList.append(round(minMax(list1[i],min(list1),max(list1)),2))\n",
        "\n",
        "print(normalizedList)\n",
        "# print(minMax(10,0,100))\n",
        "# print(minMax(199,198,200))\n",
        "\n"
      ],
      "metadata": {
        "id": "ixNCF-uhe17J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e513b08-09b0-4282-a76a-536ac952cc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09, 0.22, 0.0, 0.55, 0.26, 1.0, 0.09]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 Normalization:\n",
        " You are given a dataset student_scores.csv that contains the scores of students in different subjects. The scores are on different scales (e.g., some are out\n",
        "of 100, others out of 50). Normalize the scores to a common scale for comparison.\n",
        " a. Normalize the scores of all subjects to a 0-1 scale using Min-Max normalization.\n",
        " b. Compare the original and normalized scores.\n",
        " Tasks:\n",
        " ❖ Load the dataset and inspect the first few rows.\n",
        " ❖ Apply Min-Max normalization to the scores of all subjects.\n",
        " ❖ Display the original and normalized scores side by side"
      ],
      "metadata": {
        "id": "f3XrmswPRLBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Making the dataset here itself\n",
        "data = {\n",
        "    'StudentID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'Math': [78, 88, 60, 90, 55, 83, 71, 64, 88, 76],\n",
        "    'Science': [65, 75, 50, 78, 48, 72, 66, 52, 80, 68],\n",
        "    'English': [80, 85, 55, 92, 58, 88, 79, 70, 90, 82]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Initial Data:\\n\", df.head())\n",
        "\n",
        "#Min max normalization\n",
        "scaler = MinMaxScaler()\n",
        "df[['Math', 'Science', 'English']] = scaler.fit_transform(df[['Math', 'Science', 'English']])\n",
        "print(\"\\nNormalized Scores:\\n\", df.head())"
      ],
      "metadata": {
        "id": "7ANsJ46kVWi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5a8cef-195d-4d2f-f03f-87eb557b23af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data:\n",
            "    StudentID  Math  Science  English\n",
            "0          1    78       65       80\n",
            "1          2    88       75       85\n",
            "2          3    60       50       55\n",
            "3          4    90       78       92\n",
            "4          5    55       48       58\n",
            "\n",
            "Normalized Scores:\n",
            "    StudentID      Math  Science   English\n",
            "0          1  0.657143  0.53125  0.675676\n",
            "1          2  0.942857  0.84375  0.810811\n",
            "2          3  0.142857  0.06250  0.000000\n",
            "3          4  1.000000  0.93750  1.000000\n",
            "4          5  0.000000  0.00000  0.081081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Data Binning\n",
        " You are given a dataset customer_ages.csv that contains the ages of customers. Perform data binning on the Age column to group customers into age\n",
        "ranges: \"Young\" (18-30), \"Middle-aged\" (31-50), and \"Senior\" (51 and above).\n",
        " a. Perform data binning on the Age column.\n",
        " b. Assign a category label to each age group.\n",
        " c. Analyze the distribution of customers across the age groups.\n",
        " Tasks:\n",
        " ❖ Load the dataset and inspect the first few rows.\n",
        " ❖ Create bins for the Age column and assign category labels.\n",
        " ❖ Calculate the number of customers in each age group."
      ],
      "metadata": {
        "id": "s9lWc9zdS8KC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {\n",
        "    'CustomerID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
        "    'Age': [25, 42, 36, 53, 28, 47, 31, 50, 22, 60, 34, 19, 45, 39, 27]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#Create bins\n",
        "bins=[10,20,40,100]\n",
        "labels=[\"Teens\",\"Peak\",\"Seniros\"]\n",
        "df['AgeGrp']=pd.cut(df['Age'],bins=bins,labels=labels,right=False)\n",
        "\n",
        "print(\"\\nData after Binning:\\n\", df.head())\n",
        "\n",
        "#Calculate the mean, median and SD of the age group\n",
        "\n",
        "ageGrp= df.groupby('AgeGrp').agg(\n",
        "    Count=('Age','count'),\n",
        "    Mean= ('Age','mean'),\n",
        "    SD=('Age','std'),\n",
        "    Min=('Age','min'),\n",
        "    Max=('Age','max'),\n",
        ")\n",
        "\n",
        "print(ageGrp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQcSv0XS-sT",
        "outputId": "f521d9b7-2814-4ab6-dac6-4a1625e4a059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after Binning:\n",
            "    CustomerID  Age   AgeGrp\n",
            "0           1   25     Peak\n",
            "1           2   42  Seniros\n",
            "2           3   36     Peak\n",
            "3           4   53  Seniros\n",
            "4           5   28     Peak\n",
            "         Count   Mean        SD  Min  Max\n",
            "AgeGrp                                   \n",
            "Teens        1  19.00       NaN   19   19\n",
            "Peak         8  30.25  5.800246   22   39\n",
            "Seniros      6  49.50  6.410928   42   60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-18-474440432.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  ageGrp= df.groupby('AgeGrp').agg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U1bZOCw1U7EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Discritization\n",
        " You are given a dataset sales_data.csv that contains the monthly sales figures of a company. The sales figures are continuous values. Discretize the sales\n",
        "data into categories such as \"Low\", \"Medium\", and \"High\" based on sales volume.\n",
        " a.\n",
        " b.\n",
        " c.\n",
        " Tasks:\n",
        " Discretize the Sales column into three categories.\n",
        " Assign a category label based on the discretized sales values.\n",
        " Analyze the distribution of sales across the categories.\n",
        " ❖ Load the dataset and inspect the first few rows.\n",
        " ❖ Apply discretization to the Sales column.\n",
        " ❖ Assign appropriate category labels and analyze the distribution"
      ],
      "metadata": {
        "id": "GB7EkfADWAQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "data={\n",
        "    'Month':['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'],\n",
        "    'Sales':  np.random.randint(200, 3001, size=12)\n",
        "    }\n",
        "df= pd.DataFrame(data)\n",
        "print(\"Initial Data:\\n\", df.head())\n",
        "# Step 2: Apply discretization\n",
        "bins = [0, 5000, 20000, float('inf')]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['SalesCategory'] = pd.cut(df['Sales'], bins=bins, labels=labels)\n",
        "print(\"\\nData after Discretization:\\n\", df.head())\n",
        "# Step 3: Analyze the distribution of sales categories\n",
        "sales_category_distribution = df['SalesCategory'].value_counts()\n",
        "print(\"\\nSales Category Distribution:\\n\", sales_category_distribution)"
      ],
      "metadata": {
        "id": "ObSWuLukWC9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed864634-c12b-4d5b-85d7-8adb93be8573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data:\n",
            "   Month  Sales\n",
            "0   jan   1060\n",
            "1   feb   1494\n",
            "2   mar   1330\n",
            "3   apr   1295\n",
            "4   may   1838\n",
            "\n",
            "Data after Discretization:\n",
            "   Month  Sales SalesCategory\n",
            "0   jan   1060           Low\n",
            "1   feb   1494           Low\n",
            "2   mar   1330           Low\n",
            "3   apr   1295           Low\n",
            "4   may   1838           Low\n",
            "\n",
            "Sales Category Distribution:\n",
            " SalesCategory\n",
            "Low       12\n",
            "Medium     0\n",
            "High       0\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Feature Selection\n",
        " You are given a dataset medical_data.csv that contains several features related to patients' medical history and a target variable indicating whether they\n",
        "have a specific disease. Perform feature selection to identify the most important features for predicting the disease.\n",
        " a. Use a feature selection method (e.g., Chi-square test, ANOVA, or correlation) to rank the features.\n",
        " b. Identify the top 3 features related to the target variable.\n",
        " c. Discuss how the selected features could influence the prediction.\n",
        " Tasks:\n",
        " ❖ Load the dataset and inspect the first few rows.\n",
        " ❖ Apply a feature selection method to rank the features.\n",
        " ❖ Identify and display the top 3 features."
      ],
      "metadata": {
        "id": "GoHEgz0mZ8g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "# Step 1: Load the dataset\n",
        "data = {\n",
        "    'PatientID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'Age': [45, 50, 60, 40, 35, 55, 42, 38, 47, 53],\n",
        "    'BloodPressure': [130, 140, 150, 120, 110, 145, 135, 115, 125, 140],\n",
        "    'Cholesterol': [180, 200, 240, 170, 160, 210, 190, 150, 170, 210],\n",
        "    'Glucose': [95, 105, 120, 90, 85, 115, 100, 80, 95, 110],\n",
        "    'HeartRate': [70, 75, 80, 65, 60, 78, 72, 68, 70, 76],\n",
        "    'Disease': [1, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Initial Data:\\n\", df.head())\n",
        "# Step 2: Define features and target variable\n",
        "X = df.drop(columns=['Disease'])\n",
        "y = df['Disease']\n",
        "# Step 3: Apply Chi-square feature selection\n",
        "selector = SelectKBest(score_func=chi2, k=3)\n",
        "selector.fit(X, y)\n",
        "# Step 4: Get the top 3 features\n",
        "top_features = X.columns[selector.get_support()]\n",
        "print(\"\\nTop 3 Features for Predicting Disease:\\n\", top_features)"
      ],
      "metadata": {
        "id": "ANlv6R3BZXlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1f30da-e620-4bc4-a568-977eaf1914bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data:\n",
            "    PatientID  Age  BloodPressure  Cholesterol  Glucose  HeartRate  Disease\n",
            "0          1   45            130          180       95         70        1\n",
            "1          2   50            140          200      105         75        1\n",
            "2          3   60            150          240      120         80        1\n",
            "3          4   40            120          170       90         65        0\n",
            "4          5   35            110          160       85         60        0\n",
            "\n",
            "Top 3 Features for Predicting Disease:\n",
            " Index(['Age', 'Cholesterol', 'Glucose'], dtype='object')\n"
          ]
        }
      ]
    }
  ]
}